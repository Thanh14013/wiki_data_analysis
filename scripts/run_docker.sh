#!/bin/bash
# scripts/run_docker.sh

# Di chuyá»ƒn ra thÆ° má»¥c gá»‘c
cd "$(dirname "$0")/.."

echo "ðŸ›   Building project structure..."

# 1. Báº­t Infrastructure
docker-compose -f infrastructure/docker/docker-compose.yml up -d
echo "â³ Waiting for Kafka & Postgres..."
sleep 15

# 2. Cháº¡y Producer (Background)
echo "ðŸ“¡ Starting Ingestion..."
export PYTHONPATH=$PYTHONPATH:$(pwd)
python3 ingestion/producer.py > logs/producer.log 2>&1 &

# 3. Cháº¡y Spark Job (Background)
echo "ðŸ”¥ Starting Spark Processing..."
# LÆ°u Ã½: Cáº§n add packages JDBC vÃ  Kafka vÃ o lá»‡nh submit
PACKAGES="org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0,org.apache.commons:commons-pool2:2.11.1"

python3 processing/stream_job.py --packages $PACKAGES > logs/spark.log 2>&1 &

echo "âœ… System is running!"